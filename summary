[모델 설명]
: 2-Stage Object Detector로 Region Proposal (탐색 영역 찾기)과 Detection(해당 영역 분류) 두 가지 과정이 순차적으로 수행되는 방법론이다. R-CNN은 Region Proposal마다 하나의 CNN을 돌리고  Bounding Box 모델을 동시에 학습해야 하니  학습에 걸리는 시간이 엄청났다. 이 문제를 해결하기 위해 Fast R-CNN이 개발되었다. Feature을 이미지로부터 뽑아내는 것이 아니라 CNN을 거친 Feature Map상에서 Rol Pooling을 사용하여 Feature을 뽑아낸다. 하나의 CNN만 돌아가면 되므로 object Detection의 수행속도가 빨라졌다. 여기에 Region Proposal을 생성하는 방식을 뉴럴 네트워크로 해결한  Faster R-CNN이 등장했다. Faster R-CNN은 Region Proposal을 생성하는 방법 자체를 CNN 내부에 네트워크 구조로 넣어놓은 모델이다. 이 네트워크를 RPN(Region Proposal Network) 이라고 하며, RPN을 통해서, RoI Pooling을 수행하는 레이어와 Bounding Box를 추출하는 레이어가 같은 특징 맵을 공유할 수 있다. 

[Faster R-CNN의 구조]
: Convolution Layer를 거쳐 입력 이미지의 특징 추출 → RPN이 feature map(출력 특징 맵)에서 Region Proposal(탐색 영역) 추출 → Rol Pooling Layer에서 Region Proposal(탐색영역)들에 대해 Rol 풀링 수행
 
[RPN의 작동 방식]
: 출력 특징 맵 위를 지정한 크기의 window가 슬라이딩하면서 각 지점마다 지정된 크기의 anchor를 지정한 개수만큼 생성한다. 모든 anchor에 대해 가능한 Bounding Box의 좌표와 그 안에 물체가 들어있을 확률을 계산한다. k개의 anchor box에 대해 각각의 위치, 크기, Bounding Box로써의 점수들을 계산한다. 
cls layer : 해당 박스 안에 물체의 존재 여부를 분류 
2k개의 점수들은 해당 anchor 내에 물체의 존재 여부 확률을 계산한다.
reg layer : Bounding box의 정확한 위치를 예측한다. 
4k개의 좌표 값들은 해당 anchor의 x,y좌표와 Width, Height값을 가지고 있다. 
두 layer들의 학습을 통해 물체가 들어있는 정확한 Bounding Box = Rol들을 추출할 수 있다.

	[Rol Pooling]
: RPN이 생성한 Rol들에 대해 각 Region에 대한 특징 맵이 모두 동일하게 고정된 사이즈로 생성되도록 함. 이를 통해 각 Rol 내 물체들의 분류를 시행할 수 있다. 

Multi-task Loss를 사용하여 모든 트레이닝을 하나의 Loss함수로 진행. RPN을 학습하기 위한 Loss와 분류기를 학습하기 위한 Loss를 더한 모습. 학습을 더 빠르게, 통합적으로 진행할 수 있다.
[코드 구성 활용 및 결과]
설치되어야하는 환경
cython
ciffi
opencv-python
scipy
msgpack
easydict
matplotlib
pyyalm
tensorboardX

결과
다음은 모델을 구현한 결과의 일부이다.

1). PASCAL VOC 2007 (Train/Test: 07trainval/07test, scale=600, ROI Align)
모델
#GPU
배치크기
lr
lr-decay
max-
epoch
시간/
epoch
mem/
GPU
mAP
VGG-16
1
1
1e-3
5
6
0.76hr
3265MB
70.1


2). COCO (Train/Test: coco_train+coco_val-minival/minival, scale=600, max_size=1000, ROI Align)
모델
#GPU
배치크기
lr
lr-decay
max-
epoch
시간/
epoch
mem/
GPU
mAP
Res-101
8
24
1e-2
4
6
5.4hr
10659MB
33.9



실행하기 위한 전제 조건
Python 2.7 or 3.6
Pytorch 0.4.0
CUDA 8.0 or higher
학습을 위한 데이터 셋
PASCAL_VOC 07 + 12
COCO
Visual Genome
: kit으로 연결되는 url 제공
pre-trained 모델
VGG16과 ResNet101을 pre-trained  모델 사용.
train 학습
CUDA_VISIBLE_DEVICES=$GPU_ID python trainval_net.py \
                   --dataset pascal_voc --net vgg16 \
                   --bs $BATCH_SIZE --nw $WORKER_NUMBER \
                   --lr $LEARNING_RATE --lr_decay_step $DECAY_STEP \
                   --cuda

다음 코드를 실행해서 faster R-CNN 모델을 훈련할 수 있다.
vgg16 대신 resnet101 대입 가능하다.
bs(batch size)의 기본 값은 1이며 batch_size와 worker_number는 GPU메모리 크기에 따라 적절하게 설정할 수있다. 12G 메모리의 Titan Xp에서는 최대 4개까지 가능하다.  
batch_size = forward와 backward를 한번에 얼만큼의 데이터씩 진행할 것인지를 의미한다. 모델의 가중치를 한번 업데이트 시킬 때마다 사용되는 샘플들의 묶음을 의미한다. 1000개의  샘플이 있는데 batchsize가 50이면 20번의 가중치 업데이트가 일어난다.
test 시험
python test_net.py --dataset pascal_voc --net vgg16 \
                   --checksession $SESSION --checkepoch $EPOCH --checkpoint $CHECKPOINT \
                   --cuda

vgg16 대신 resnet101 대입 가능하다.
session, epoch, checkpoint를 설정한다. (예 : SESSION = 1, EPOCH = 6, CHECKPOINT = 416).
epoch : 모든 트레이닝 데이터에 대해서 forward와 backward pass를 진행한 상태를 의미한다. 학습의 횟수를 의미한다. 20번의 가중치 업데이트가 있을 때 epoch가 6번이면 120번 가중치 업데이트된다.
check point : 재개를 위한 저장 포인트
 
demo code

python demo.py --net vgg16 \
               --checksession $SESSION --checkepoch $EPOCH --checkpoint $CHECKPOINT \
               --cuda --load_dir path/to/model/directoy

ROOT/ images 폴더에서 탐지 결과를 찾을 수 있다.
데모 코드는 VOC 데이터셋 카테고리만 지원하므로 라인을 수정해서 적용하면 된다.



감지 결과



 활용분야
딥러닝이 등장하면서 카메라 영상을 이용하여 차량, 보행자, 도로등을 인지하는 자율주행  기술이 발전하고 있다. Faster R-CNN은 물체 탐지 기법중 빠른 처리 속도를 보여주며 조도에 강하다고 알려져있다. 따라서 전방 끼어들기 차량에 대한 감지를 위해 Faster R-CNN을 이용하여 차량 종류, 끼어들기 상태에 따른 차량 부분 형상, 색, 환경 인자(조도, 배경 등)의 변화에 대한 차량 감지 성능 영향을 분석한 연구가 진행되었다. 도로 상황에서 빈번하게 검출되는 신호등, 사람, 교통 표지판, 차량을 실시간으로 Embdded Board 환경에서 검출할 수 있도록 경량화하는 연구 등에서도 정확도가 높은 Faster R-CNN이 객체 탐지를 위해 사용되었다. 
